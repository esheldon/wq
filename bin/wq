#!/usr/bin/env python
"""
    %prog [options] command [command options]

Basic command modes are the following.  There are additional
options for each command

    sub:        Submit a job.
    ls:         Print the job listing
    stat:       Get the status of the cluster/queue.
    rm:         Remove a job or all jobs for a user.
    refresh:    Force a refresh of the job queue.
    limit:      Place limits on a user such as Ncores or Njobs.
    serve:      Run a server.
    node: 	Set systems from offline to online or vice versa.

To get help on each command, use -h, for example
    %prog sub -h
    %prog rm -h

Note: additional basic setup options, *before* the command
is processed, are
    -p: port number
e.g.
    wq -p port sub ...
"""
from __future__ import print_function

import socket
import sys
from sys import stderr
import yaml
from yaml import YAMLError
import os
import signal
import wq
import time
import subprocess
from subprocess import SubprocessError
import uuid

from optparse import OptionParser

# need to move this into server.py and require a real installation
_COMMANDS = ['serve', 'sub', 'ls', 'stat', 'rm', 'refresh']


def yaml_load(obj):
    return yaml.load(obj, Loader=yaml.SafeLoader)


class ServerWrapper(object):
    """
    usage: wq serve cluster_def_file

    The def file is one line per node

        hostname ncores mem groups

    The groups are an optional comma separate list.
    """
    def __init__(self, port, args):
        import wq
        parser = OptionParser(ServerWrapper.__doc__)
        parser.add_option("-s", "--spool-dir", default=None,
                          help="use the specified spool dir")
        parser.add_option("--loglevel", default='info',
                          help="logging level")

        options, args = parser.parse_args(args)
        spool_dir = options.spool_dir
        if spool_dir is None:
            spool_dir = wq.DEFAULT_SPOOL_DIR

        spool_dir = os.path.expanduser(spool_dir)

        if len(args) < 1:
            parser.print_help()
            sys.exit(1)

        if args[0] == '-h':
            parser.print_help()
            sys.exit(1)

        # these keywords get passed all the way down to JobQueue and Job
        self.server = wq.server.Server(
            cluster_file=args[0],
            port=port,
            spool_dir=spool_dir,
            loglevel=options.loglevel,
        )

    def execute(self):
        self.server.run()


class JobLister(dict):
    """
    usage: wq ls [options]

    print the job list to stdout.

    If -u/--user is sent, the listing is restricted to that user/users.

    If -f/--full is sent, the full job listing is given.  This is a yaml
    document that can be read and processed to provide a customised
    listing.
    """

    def __init__(self, port, args):
        self.port = port
        self._process_args(args)

    def _process_args(self, args):
        parser = OptionParser(JobLister.__doc__)
        parser.add_option("-u", "--user", default=None,
                          help=("Only list jobs for the user.  can be "
                                "a comma separated list"))
        parser.add_option("-f", "--full", action='store_true',
                          help="Give a full job listing as a YAML stream.")

        options, args = parser.parse_args(args)
        self.user = options.user
        self.full = options.full

        if self.user is not None:
            self.user = self.user.split(',')

    def execute(self):
        message = {}
        message['command'] = 'ls'
        resp = send_message(self.port, message)

        if self.full:
            if self.user is not None:
                show = [r for r in resp['response'] if r['user'] in self.user]
            else:
                show = resp['response']
            if len(show) > 0:
                print(yaml.dump(show))

            return

        names = ['pid', 'user', 'st', 'pri', 'nc',
                 'nh', 'host0', 'Tq', 'Trun', 'cmd']

        lens = {}
        for k in names:
            lens[k] = len(k)

        nrun = 0
        nwait = 0
        lines = []
        timenow = time.time()
        for r in resp['response']:
            if 'user' not in r:
                continue

            if self.user is None or r['user'] in self.user:
                if r['status'] == 'run':
                    nrun += 1
                else:
                    nwait += 1

                this = {}
                this['pid'] = r['pid']
                this['user'] = r['user']
                this['pri'] = r['priority']
                this['st'] = self._get_status(r)
                this['nc'] = self._get_ncores(r)
                # this may replace command with job_name, if it exists
                this['cmd'] = self._get_command(r)
                this['Tq'] = self._get_time_in(r, timenow)
                this['Trun'] = self._get_time_run(r, timenow)

                this['nh'] = self._get_nhosts(r)

                # this is the first host on the list
                this['host0'] = self._get_host0(r)

                # for sorting
                this['time_sub'] = r['time_sub']

                for k in this:
                    if k in lens:
                        lens[k] = max(lens[k], len(('%s' % this[k])))

                lines.append(this)

        fmt = []
        for k in names:
            if k in ['Tq', 'Trun']:
                align = ''
            else:
                align = '-'

            fmt.append('%('+k+')'+align+str(lens[k])+'s')

        fmt = ' '.join(fmt)
        fmt = ' '+fmt

        # this is the header for each column
        if len(lines) > 0:
            print(
                fmt % {'pid': 'Pid', 'user': 'User',
                       'st': 'St', 'pri': 'Pri', 'nc': 'Nc',
                       'nh': 'Nh', 'host0': 'Host0',
                       'cmd': 'Cmd', 'Tq': 'Tq', 'Trun': 'Trun'}
            )

        for line in sorted(lines, key=lambda x: x['time_sub']):
            print(fmt % line)

        njobs = nrun+nwait
        stats = 'Jobs: %s Running: %s Waiting: %s' % (njobs, nrun, nwait)
        if self.user is not None:
            print(' User: %s %s' % (','.join(self.user), stats))
        else:
            print(' %s' % stats)

    def _get_ncores(self, r):
        if r['status'] == 'run':
            return len(r['hosts'])
        else:
            return '-'

    def _time_diff(self, dt):
        # surprisingly, there is nothing like this in date or time modules
        ds = int(dt)
        nd = int(ds/(24*60*60))
        ds -= nd*24*60*60
        nh = int(ds/(3600))
        ds -= nh*3600
        nm = int(ds/60)
        ds -= nm*60
        ns = ds

        r = ''

        if nd > 0:
            r = '%dd%02dh%02dm' % (nd, nh, nm)
        elif nh > 0:
            r = '%02dh%02dm%02ds' % (nh, nm, ns)
        elif nm > 0:
            r = '%02dm%02ds' % (nm, ns)
        else:
            r = '%02ds' % ns

        return r

    def _get_time_in(self, r, timenow):
        return self._time_diff(timenow-r['time_sub'])

    def _get_time_run(self, r, timenow):
        if r['status'] == 'run':
            return self._time_diff(timenow-r['time_run'])
        else:
            return '-'

    def _get_host0(self, r):
        """
        Get the first host in the list
        """
        if r['status'] != 'run':
            return '-'

        if not r['hosts']:
            return '-'
        else:
            return r['hosts'][0]

    def _get_nhosts(self, r):
        if r['status'] == 'run':
            hd = {}
            for host in r['hosts']:
                hd[host] = host
            return len(hd)
        else:
            return '-'

    def _get_status(self, r):
        if self.full:
            if r['status'] == 'run':
                return 'running'
            else:
                return r['reason']
        else:
            if r['status'] == 'run':
                return 'R'
            else:
                return 'W'

    def _get_command(self, r):
        c = r['job_name']

        # remove spaces from name so we can use awk on
        # the output of wq ls
        c = '-'.join(str(c).split())
        return c


class Stats(dict):
    """
    usage: wq stat

    print the status of the queue and compute cluster
    """

    def __init__(self, port, args):
        self.port = port
        parser = OptionParser(Stats.__doc__)
        options, args = parser.parse_args(args)

    def execute(self):
        message = {}
        message['command'] = 'stat'

        resp = send_message(self.port, message)

        status = resp['response']

        wq.server.print_stat(status)


class UsersLister(dict):
    """
    usage: wq users

    print user info for the system
    """

    def __init__(self, port, args):
        self.port = port
        parser = OptionParser(Stats.__doc__)
        options, args = parser.parse_args(args)

    def execute(self):
        message = {}
        message['command'] = 'users'

        resp = send_message(self.port, message)

        users = resp['response']

        wq.server.print_users(users)


_LIMIT_VALID_KEYS = ['Njobs', 'Ncores']


class Limiter(dict):
    """
    usage: wq limit "key1:val1; key2:val2; ..."

    Place limits on the user such as
        wq limit "Njobs: 10"
        wq limit "Ncores: 120"
        wq limit "Ncores: 120; Njobs: 25"

    To clear your limits
        wq limit clear

    To see your current limits
        wq users
    """

    def __init__(self, port, args):
        self.port = port
        parser = OptionParser(Limiter.__doc__)
        options, args = parser.parse_args(args)

        if len(args) < 1:
            parser.print_help()
            sys.exit(1)

        if args[0] == 'clear':
            self.limits = {'action': 'clear'}
        else:
            self.limits = _process_singleline_yaml(args[0])

            for key in self.limits:
                if key not in _LIMIT_VALID_KEYS:
                    mess = "limit should be one of %s, got: '%s'"
                    raise ValueError(mess % (_LIMIT_VALID_KEYS, key))
            self.limits['action'] = 'set'

    def execute(self):
        message = {}
        message['command'] = 'limit'
        message['user'] = os.environ['USER']
        message['limits'] = self.limits

        resp = send_message(self.port, message)

        print(resp['response'], file=stderr)


class NodeCommand(dict):
    """
    usage: wq node machine status_specification

    set a node from offline to online or vice versa

    To set a node offline
        wq node machine_name "status:offline"

    To set a node online
        wq node machine_name "status:online"

    You can set multiple machines
        wq node machine1 machine2 "status:online"
    """

    def __init__(self, port, args):
        self.port = port
        parser = OptionParser(NodeCommand.__doc__)
        options, args = parser.parse_args(args)

        if len(args) < 2:
            parser.print_help()
            sys.exit(1)
        self.node = args[0]
        self.yamline = _process_singleline_yaml(args[1])

    def execute(self):
        message = {}
        message['command'] = 'node'
        message['user'] = os.environ['USER']
        message['node'] = self.node
        message['yamline'] = self.yamline
        resp = send_message(self.port, message)
        print(resp['response'], file=stderr)


class Refresher(dict):
    """
    usage: wq refresh

    Request that the server refresh it's job list
    """

    def __init__(self, port, args):
        self.port = port
        parser = OptionParser(Refresher.__doc__)
        options, args = parser.parse_args(args)

    def execute(self):
        message = {}
        message['command'] = 'refresh'

        send_message(self.port, message)


class Remover(dict):
    """
    usage: wq rm pid1 pid2 ....

    Request that the server remove the specified job or jobs. Use "wq rm all"
    to remove all of your jobs.
    """

    def __init__(self, port, args):
        self.port = port
        parser = OptionParser(Remover.__doc__)
        options, args = parser.parse_args(args)

        if len(args) < 1:
            parser.print_help()
            sys.exit(1)

        pid = args[0]
        if pid == 'all':
            self.pid = ['all']
        else:
            self.pid = [int(p) for p in args]

    def execute(self):
        for pid in self.pid:
            self.do_remove(pid)

    def do_remove(self, pid):
        message = {}
        message['command'] = 'rm'
        message['pid'] = pid
        message['user'] = os.environ['USER']

        resp = send_message(self.port, message)

        if resp['response'] == 'OK':
            if 'pids_to_kill' not in resp:
                raise RuntimeError(
                    "server did not return pids_to_kill."
                )

            # this is always a list, for when we do "wq rm all"
            pids_to_kill = resp['pids_to_kill']
            for pidtokill in pids_to_kill:

                os.kill(pidtokill, signal.SIGTERM)
                time.sleep(0.1)  # sleep  a bit
                cc = 0

                # see when it disappears, up to 10sec
                while (self._pid_exists(pidtokill) and (cc < 100)):
                    time.sleep(0.1)
                    cc += 1

                if self._pid_exists(pidtokill):
                    # SIGTERM did not work, try stronger SIGKILL
                    os.kill(pidtokill, signal.SIGKILL)
                    time.sleep(1)

            # Now refresh to remove it from queue
            message = {}
            message['command'] = 'refresh'
            resp = send_message(self.port, message)

        else:
            print("Cannot remove, reason=", resp['error'], file=stderr)

    def _pid_exists(self, pid):
        """ Check For the existence of a unix pid. """
        try:
            # this doesn't actually kill the job, it does nothing if the pid
            # exists, if doesn't exist raises OSError
            os.kill(pid, 0)
        except OSError:
            return False
        else:
            return True


def _process_singleline_yaml(data):
    import re

    yaml_data = {}
    if data is None:
        return yaml_data

    # convert semicolon to newline
    r = re.sub(r';\s*', '\n', data)

    # make sure there is a space between : and value
    r = r.replace(':', ': ')

    yaml_data = yaml_load(r)

    if not isinstance(yaml_data, dict):
        raise TypeError("could not parse input as yaml: '%s'" % data)

    return yaml_data


class Submitter(dict):
    """
    usage: wq sub [options] [args]

    There are three modes.  Note you can add -r/--require to each of these
    *except* batch mode.  -r/--require will over-ride requirements in job
    files.

        - Send a command as an argument.

                wq sub -c command

          The command is just a string.  You probably want to double quote it
        - Submit a job file

                wq sub job_file

          The job stays in the foreground, so this is only useful for
          interactive jobs where you need to specify complex job requirements.

        - Submit one or more job files in batch mode.

                wq sub -b job_file1 job_file2 ....

          Each job will be submitted in the background.  This is the preferred
          method for non-interactive jobs.

    """
    def __init__(self, port, args):
        self.port = port
        self._process_args(args)

    def _process_args(self, args):
        parser = OptionParser(Submitter.__doc__)
        parser.add_option("-r", "--require",
                          default=None, help="optional requirements for job")
        parser.add_option("-b", "--batch", action='store_true',
                          help="Submit jobs in batch mode.")
        parser.add_option("-c", "--command", default=None,
                          help="The command to run as a string")

        options, args = parser.parse_args(args)

        self['require_opt'] = options.require

        # batch mode is special; just store the job files and let
        # execute() deal properly with them
        self.isbatch = False
        if len(args) > 0 and options.batch:
            # we just store the files and later run them when
            # execute is done
            self.isbatch = True
            self.job_files = args[:]
            return

        if options.command is not None:
            commandline = options.command
            reqs = {}
        elif len(args) > 0:
            # a job file was sent
            job_file = args[0]
            commandline, reqs = self._process_job_file(job_file)
        else:
            raise ValueError

        if commandline is None:
            parser.print_help()
            sys.exit(1)

        # requirements sent using -r/--require over-ride
        reqs_from_opt = _process_singleline_yaml(self['require_opt'])

        for ro in reqs_from_opt:
            reqs[ro] = reqs_from_opt[ro]

        self['commandline'] = commandline
        self['require'] = reqs

    def _batch_submit_joblist(self, job_files):
        njob = len(job_files)
        for f in job_files:
            self._batch_submit_job(f)
            if njob > 1:
                time.sleep(1)

    def _batch_submit_job(self, job_file):
        """
        For batch mode we call wq again with a single job file and
        no requirements
        """

        print('submitting', job_file, file=stderr)
        port = str(self.port)

        req = ''
        if self['require_opt'] is not None:
            req = '-r "%s"' % self['require_opt']

        command = """
            nohup wq -p "{port}" sub {req} "{jobf}" > "{logf}" 2>&1 &
        """.format(port=port,
                   jobf=job_file,
                   logf=job_file+'.wqlog',
                   req=req)
        os.system(command)

    def _process_job_file(self, fname):

        reqs = yaml_load(open(fname))

        if not isinstance(reqs, dict):
            raise TypeError("could not parse job file as yaml: '%s'" % fname)

        if 'command' not in reqs:
            raise ValueError("no command found in job file")
        commandline = reqs['command']

        # don't need this in the requirements
        del reqs['command']

        return commandline, reqs

    def _process_require_opt(self, require_opt):
        import re

        reqs = {}
        if require_opt is None:
            return reqs

        # convert semicolon to newline
        r = re.sub(r';\s*', '\n', require_opt)

        # make sure there is a space between : and value
        r = r.replace(':', ': ')

        reqs = yaml_load(r)

        if not isinstance(reqs, dict):
            raise TypeError("could not parse requirements as yaml: '%s'" % r)

        return reqs

    def receive_signal(self, a, b):
        pass

    def receive_kill(self, a, b):
        try:
            self.remoteprocess.terminate()
        except SubprocessError:
            pass

        self.message['command'] = 'notify'
        self.message['notification'] = 'done'
        sres = send_message(self.port, self.message)
        self.print_res(sres)
        sys.exit(0)

    def make_command_list(self, target_machine, command, require):
        # full command, we first change directory to CWD
        pwd = os.getcwd()
        if 'precmd' in self.rcdata:
            full_command = self.rcdata['precmd']+" ; "
        else:
            full_command = ""
        full_command += 'cd '+pwd+'; '+command

        # replace %hostfile% with actual hostfile
        if self.hostfile:
            full_command = full_command.replace('%hostfile%', self.hostfile)

        if 'threads' in self['require']:
            full_command = full_command.replace(
                '%threads%',
                str(self['require']['threads']),
            )

        if target_machine == 'localhost':
            shell = os.environ['SHELL']
            cmdlist = [shell, '-c', command]
        else:
            # first, force pseudo tty; this is key to make sure command
            # dies if this client dies
            # also -A forwards ssh agent
            cmdlist = ['ssh', '-t', '-t', '-A']

            # should we forward X? default is no no.  This is in the
            # requirements as
            #   X: true or X: 1 for yes (anything evaluates as True in python)
            #   X: false or X: 0 for no

            xforward = require.get('X', False)
            if xforward:
                cmdlist.append('-X')
            else:
                cmdlist.append('-x')

            cmdlist.append(target_machine)
            cmdlist.append(full_command)

        return cmdlist

    def prepare_hostlist(self, hostlist):
        if 'threads' in self['require']:
            th = self['require']['threads']
            if th <= 0:
                print('Bad value for threads %s. Ignoring.' % th)

            elif th > 1:
                dct = {}
                for h in hostlist:
                    if h in dct:
                        dct[h] += 1
                    else:
                        dct[h] = 1

                nhostlist = []
                for h in dct:
                    n = dct[h]
                    if n % th != 0:
                        print('Host', h, 'has',
                              n % th, 'dangling cores. Ignoring.')

                    for i in range(n/th):
                        nhostlist.append(h)

                hostlist = nhostlist

        return hostlist

    def execute(self):
        """
        - build the message request for the server.
        - send the message and await reply
        - Maybe wait until we can run
        - ssh into the target machine and run the job in the same
          directory where this client is running.

        For MPI jobs, a host file can be created.
        """

        if self.isbatch:
            self._batch_submit_joblist(self.job_files)
            return

        message = {}
        message['command'] = 'sub'
        message['pid'] = os.getpid()
        message['user'] = os.environ['USER']
        message['require'] = self['require']
        message['commandline'] = self['commandline']

        sres = send_message(self.port, message)

        if sres['response'] == 'wait':
            # wait until we can go
            print('waiting:', sres['reason'], file=stderr)
            fname = sres['spool_fname']
            wsleep = sres['spool_wait']
            while True:
                time.sleep(wsleep)
                try:
                    open(fname)
                    print("ok", file=stderr)
                    break
                except IOError:
                    pass

            message['command'] = 'get_hosts'
            sres = send_message(self.port, message)

        # save final message for potential kill
        self.message = message

        # if hostfile specified need to create one
        hosts = sres['hosts']

        reqs = self['require']
        if 'host_file' in reqs:
            self.hostfile = reqs['host_file']
        elif 'hostfile' in reqs:
            self.hostfile = reqs['hostfile']
        else:
            self.hostfile = None

        if self.hostfile is not None:
            if self.hostfile == 'auto':
                self.hostfile = str(uuid.uuid4())[:8]+'.hostfile'
            else:
                self.hostfile = self['require']['hostfile']

            with open(self.hostfile, 'w') as fobj:
                for h in self.prepare_hostlist(hosts):
                    fobj.write(h+'\n')

        target = hosts[0]
        command = self['commandline']
        print(command)

        print(
            'executing on host: %s '
            'with pid: %s' % (target, message['pid']),
            file=stderr,
        )
        signal.signal(signal.SIGTERM, self.receive_kill)

        cmdlist = self.make_command_list(target, command, self['require'])
        self.remoteprocess = subprocess.Popen(cmdlist)
        self.remoteprocess.wait()

        # now we notify done.
        message['command'] = 'notify'
        message['notification'] = 'done'

        # Try to remove hostfile
        if self.hostfile is not None:
            try:
                os.remove(self.hostfile)
            except FileNotFoundError:
                pass

        # we want to die if the notification fails so the server will see
        # the missing pid
        sres = send_message(self.port, self.message)
        if sres['response'] != 'OK':
            print('Bad response from server:')
            self.print_res(sres)

    def print_res(self, res):
        import pprint
        for k in res:
            kk = k+': '
            pf = pprint.pformat(res[k])
            print('%-15s %s' % (kk, pf), file=stderr)


def socket_connect(sock, conninfo, crash_on_timeout=False):
    """
    crash will only happen if timeouts have been enabled, otherwise we just
    wait
    """
    if crash_on_timeout:
        sock.connect(conninfo)
    else:
        while True:
            try:
                sock.connect(conninfo)
                break
            except socket.timeout:
                pass


def send_message(port, message, timeout=None, crash_on_timeout=False):

    if len(message) == 0:
        raise ValueError("message must have len > 0")

    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    # make sure to set timeout *before* calling connect()
    if timeout is not None:
        sock.settimeout(timeout)

    conninfo = (wq.HOST, port)
    socket_connect(sock, conninfo, crash_on_timeout=crash_on_timeout)

    rdict = None
    try:
        jmess = yaml.dump(message)

        wq.server.socket_send(sock, jmess)
        data = wq.server.socket_recieve(sock, wq.BUFFSIZE)

        sock.close()

        try:
            rdict = yaml_load(data)
        except YAMLError as err:
            print(str(err), file=stderr)
            print(data, file=stderr)
            sys.exit(1)

        if 'error' in rdict:
            raise RuntimeError("Error reported by server: %s" % rdict['error'])

        if 'response' not in rdict:
            raise RuntimeError("Internal error. Expected a response "
                               "and got screwed.")

    finally:
        sock.close()

    if rdict is None:
        sys.exit(1)

    return rdict


def get_command_obj(port, args):
    if args[0] == 'sub':
        command_class = Submitter
    elif args[0] == 'ls':
        command_class = JobLister
    elif args[0] == 'stat':
        command_class = Stats
    elif args[0] == 'users':
        command_class = UsersLister
    elif args[0] == 'limit':
        command_class = Limiter
    elif args[0] == 'rm':
        command_class = Remover
    elif args[0] == 'refresh':
        command_class = Refresher
    elif args[0] == 'serve':
        command_class = ServerWrapper
    elif args[0] == 'node':
        command_class = NodeCommand
    else:
        return None

    return command_class(port, args[1:])


def preprocess_args(args, parser):
    """
    Ready the args for input to the commands.

    We hand-craft this because the options are variable for the commands, so we
    can't use optparse for that.
    """

    if len(args) == 0:
        parser.print_help()
        sys.exit(1)

    if args[0] == '-h':
        parser.print_help()
        sys.exit(1)

    try:
        ind = args.index('-p')
    except ValueError:
        ind = None

    if ind is not None:
        try:
            port = int(args[ind+1])
            del args[ind:ind+2]
        except ValueError:
            raise ValueError("bad integer port value: '%s'" % args[ind+1])
    else:
        port = wq.DEFAULT_PORT

    # now we can get the actual command, if it exists
    if len(args) == 0:
        parser.print_help()
        sys.exit(1)

    return port, args


def load_rcfile():
    fname = os.environ['HOME']+'/.wqrc'
    if os.path.exists(fname):
        rcdata = yaml_load(open(os.environ['HOME']+'/.wqrc'))
    else:
        rcdata = {}

    return rcdata


def main():

    parser = OptionParser(__doc__)

    # this won't be used in the usual way
    parser.add_option("-p", "--port", help="port for socket")

    port, args = preprocess_args(sys.argv[1:], parser)

    cmd_obj = get_command_obj(port, args)

    if cmd_obj is None:
        parser.print_help()
        sys.exit(1)

    # wq configuration
    rcdata = load_rcfile()
    cmd_obj.rcdata = rcdata

    try:
        cmd_obj.execute()
    except KeyboardInterrupt:
        pass
    except IOError:
        # this is most certainly a "broken pipe" type error when someone pipes
        # to head or something
        es = str(sys.exc_info())
        if 'Broken pipe' not in es:
            raise
    finally:
        # this helps with pipes, needed in addition to above catch of IOError
        sys.stdout.flush()
        # try:
        #     sys.stdout.flush()
        # except:
        #     pass


if __name__ == "__main__":
    main()
